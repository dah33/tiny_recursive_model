# lightning.pytorch==2.5.5
#
# Smaller model and batches for RTX 2060 (6GB):
# > uv run tiny_recursive_model.main --config config_base.yaml --config config_2060.yaml
#
# For a fast fail, add this at command line:
# > --trainer.fast_dev_run=true
compile: false  # not beneficial with gradient accumulation on small GPU
trainer:
  accumulate_grad_batches: 4  # Process 4Ã—192=768 samples before optimizer step
data:
  batch_size: 192  # Smaller batches for 6GB VRAM
model:
  n_layers: 2
  T: 2
  n: 2
  N_supervision: 1
